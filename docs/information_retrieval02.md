# 정보 검색 (Information Retrieval, IR) 학습

## 1. 정보 검색(IR) 시스템 평가 (Retrieval Evaluation)

- **IR 시스템 평가의 핵심 목표**: 사용자의 정보 요구(Information Need)를 얼마나 잘 만족시키는가를 측정하는 것입니다. 이는 단순히 검색 속도나 반환 문서 수보다 근본적인 품질 척도입니다.
- **정보 요구의 정량화**:
    - 사용자 쿼리(Query)를 통해 정보 요구를 파악합니다.
    - 정보 요구의 유형: 탐색적(Navigational), 정보형(Informational), 거래형(Transactional).
- **만족도의 정량화**:
    - 결과 클릭률 증가, 반복/증가된 방문, 결과의 관련성(Relevance) 등을 통해 간접적으로 측정합니다.
- **고전적 IR 평가 - 크랜필드 실험 (Cranfield Experiments)**:
    - IR 평가의 기초가 된 실험입니다.
    - **기본 가정**: 검색된 문서의 관련성이 사용자의 정보 요구 만족도를 잘 대변한다는 것입니다.
    - **필수 요소**:
        1. 문서 컬렉션 (Document Collection)
        2. 정보 요구를 표현하는 테스트 쿼리 집합 (Test Suite of Information Needs)
        3. 각 (쿼리, 문서) 쌍에 대한 관련성 판단 (Relevance Judgments, 예: 이진값 - 관련 있음/없음)
- **검색 관련성 (Search Relevance)**:
    - 쿼리 자체가 아닌, 쿼리 뒤에 숨겨진 사용자의 **정보 요구**에 대해 관련성을 판단해야 합니다.
- **TREC (Text REtrieval Conference)**: 1992년부터 NIST 주관으로 열리는 대규모 텍스트 검색 방법론 평가 학회로, IR 연구의 표준 벤치마크 역할을 합니다.
- **평가 지표 (Evaluation Metrics)**:
    - **비순위형 검색 결과 평가 (Unranked Retrieval Sets - 예: Boolean Retrieval)**:
        - **정밀도 (Precision, P)**: 검색된 문서 중 관련 있는 문서의 비율 ($P = TP / (TP + FP)$).
        - **재현율 (Recall, R)**: 전체 관련 문서 중 검색된 문서의 비율 ($R = TP / (TP + FN)$).
        - **F-점수 (F-measure)**: 정밀도와 재현율의 조화 평균. $F_1 = 2PR / (P+R)$ (정밀도와 재현율에 동일 가중치).
            - 조화 평균을 사용하는 이유: 한쪽 값이 극단적으로 낮은 경우에도 전체적인 성능을 잘 반영하기 위함.
    - **순위형 검색 결과 평가 (Ranked Retrieval Results)**:
        - **정밀도-재현율 곡선 (Precision-Recall Curve)**: 다양한 재현율 수준에서의 정밀도를 보여주는 그래프. (톱니 모양)
        - **보간 정밀도 (Interpolated Precision)**: 특정 재현율 $r'$보다 크거나 같은 모든 재현율 $r$에서의 정밀도 중 최댓값. ($P_{interp}(r') = \max_{r \ge r'} P(r)$)
        - **11점 보간 평균 정밀도 (Eleven-point Interpolated Average Precision)**: 0부터 1까지 0.1 간격의 11개 재현율 지점에서 보간 정밀도의 평균을 계산.
        - **P@K (Precision at K)**: 상위 K개 검색 결과에서의 정밀도. (예: P@3 - 상위 3개 중 관련 문서 비율)
        - **MAP (Mean Average Precision)**: 각 쿼리에 대한 Average Precision(AP)의 평균.
            - **AP (Average Precision)**: 각 관련 문서가 검색된 순위에서의 정밀도 값들의 평균.
            - MAP는 여러 쿼리에 대한 시스템 전체 성능을 나타내며, 사용자가 많은 관련 문서를 찾고자 할 때 유용합니다.
        - **MRR (Mean Reciprocal Rank)**: 첫 번째 관련 문서의 순위의 역수(Reciprocal Rank, RR)의 평균. ($RR = 1/rank_{first\_relevant}$)
            - 사용자가 단 하나의 정답을 찾고자 하는 경우(사실 검색, 알려진 항목 검색, 탐색적 쿼리, 쿼리 자동 완성 등)에 유용합니다. 사용자의 노력(검색 시간)을 반영합니다.
        - **NDCG (Normalized Discounted Cumulative Gain)**:
            - **DCG (Discounted Cumulative Gain)**: 관련성의 등급(Graded Relevance)을 사용하며, 순위가 낮을수록 가중치를 낮게(할인, Discount) 부여하여 누적 합산.
                - $DCG_p = rel_1 + \sum_{i=2}^{p} \frac{rel_i}{\log_2 i}$ 또는 $DCG_p = \sum_{i=1}^{p} \frac{2^{rel_i} - 1}{\log_2 (i+1)}$
            - **NDCG**: DCG를 이상적인 순위(IDCG)로 정규화하여 다른 쿼리 간 성능 비교를 용이하게 함. ($NDCG_p = DCG_p / IDCG_p$)
            - 다양한 관련성 수준을 고려하고 순위도 반영하는 강력한 지표.
- **통계적 유의성 검정 (Statistical Significance Tests)**:
    - 관찰된 성능 차이가 단순히 특정 쿼리 선택에 의한 우연인지 아닌지를 판단.
    - **p-value**: 귀무 가설(차이가 없다)이 참일 때 관찰된 데이터만큼 극단적인 데이터가 나올 확률. p-value가 작을수록 귀무 가설을 기각하고 차이가 유의미하다고 판단.
    - **주요 검정 방법**: 부호 검정(Sign Test), 윌콕슨 부호 순위 검정(Wilcoxon Signed Rank Test), 대응 표본 t-검정(Paired t-test).
- **평가자 일관성 (Assessor Consistency)**:
    - 관련성 판단은 주관적일 수 있으나, 연구에 따르면 평가자 간 불일치가 시스템 간 상대적 비교에는 큰 영향을 미치지 않는 경우가 많습니다.
    - **카파 통계량 (Kappa Statistic)**: 평가자 간의 합의 정도를 측정.
- **풀링 (Pooling)**: 대규모 컬렉션에서 모든 문서에 대한 관련성 판단이 어려울 때, 여러 시스템의 상위 k개 결과를 모아 평가하는 방식.

## 2. 현대 검색 평가 방식 (Modern Retrieval Evaluations)

- **전통적 IR 평가의 가정과 한계**:
    - 가정 1: 만족도 = 결과 관련성.
    - 가정 2: 관련성 = 독립적인 주제적 관련성 (문서는 독립적으로 판단).
    - 가정 3: 사용자는 결과를 위에서부터 순차적으로 탐색.
    - 고려되지 않은 요소: 사용자 인터페이스, 사용자의 노력 등.
- **사용자 선호도와 평가 지표의 관계 (Sanderson et al. SIGIR’10)**:
    - 일반적으로 IR 평가 지표는 사용자 선호도와 일치하는 경향이 있음.
    - 성능 차이가 클수록 사용자의 동의율이 높아짐.
- **사용자 행동 기반 평가 (User Behavior Oriented Retrieval Evaluation)**:
    - 저비용, 대규모, 실제 사용 환경에서의 평가 가능.
    - **A/B 테스트**: 두 시스템(A, B)을 무작위 사용자 그룹에 할당하여 행동 지표 비교.
        - **행동 기반 지표**: 포기율(Abandonment Rate), 재형성률(Reformulation Rate), 세션당 쿼리 수, 쿼리당 클릭 수, MRR (클릭 기반), 첫/마지막 클릭까지의 시간 등.
    - **인터리빙 테스트 (Interleave Test)**:
        - 동일 사용자에게 두 시스템(A, B)의 결과를 섞어서(interleave) 보여주고, 어느 시스템의 결과에 더 많이 클릭하는지 등을 통해 선호도 판단.
        - A/B 테스트보다 더 민감하고 정확하게 시스템 차이를 감지할 수 있음. (예: Team-draft interleaving)
- **검색 작업 만족도 평가 (Task-level Satisfaction Evaluation)**:
    - 단일 쿼리가 아닌, 사용자가 특정 목표를 달성하기 위해 수행하는 일련의 검색 작업 전체에 대한 만족도 평가.
    - 마르코프 모델 등을 사용하여 사용자의 순차적 검색 행동 패턴 분석 및 만족도 예측. (Ahmed et al. WSDM’10)

## 3. 부울 모델 (Boolean Model)

- **부울 쿼리**: AND, OR, NOT과 같은 논리 연산자를 사용하여 쿼리 작성. (예: "obama" AND "healthcare" NOT "news")
- **검색 절차**:
    1. 쿼리 용어를 사전(Dictionary)에서 조회.
    2. 각 용어에 해당하는 포스팅 리스트(Posting List) 검색.
    3. 논리 연산 수행 (AND: 교집합, OR: 합집합, NOT: 차집합).
- **장점**: 사용자가 원하는 조건을 명확히 지정하여 부분집합을 정확히 얻을 수 있음.
- **단점 (Deficiency)**:
    - **정확한 쿼리 작성의 어려움**:
        - 과도하게 제약된 쿼리(Over-constrained): 관련 문서 없음.
        - 너무 일반적인 쿼리(Under-constrained): 너무 많은 결과 반환.
    - 모든 사용자가 부울 쿼리를 선호하거나 잘 사용하지 못함.
    - 검색된 모든 문서가 동등하게 중요하지 않음 (순위화 부재). **관련성은 정도의 문제!**
- **문서 필터링(Filtering) vs. 랭킹(Ranking)**: 부울 모델은 필터링에 가깝지만, 실제로는 랭킹이 더 선호됨.
- **현대 IR에서의 활용**: 부울 모델은 초기 후보군을 필터링하고, 이후 랭킹 모델로 순위를 매기는 방식으로 활용될 수 있음.

## 4. 벡터 공간 모델 (Vector Space Model, VSM)

- **핵심 아이디어**: 문서와 쿼리를 동일한 고차원 벡터 공간(Concept Space)에 벡터로 표현하고, 이들 간의 유사도(Similarity)를 계산하여 관련성(Relevance)을 측정합니다. ($Relevance(d,q) \propto Similarity(d,q)$)
- **가정**:
    - 쿼리와 문서는 같은 형태로 표현됨 (쿼리도 하나의 문서로 간주).
- **주요 고려 사항**:
    1. **문서/쿼리 표현 방법**: 어떤 "기본 개념(Basic Concept)"으로 벡터 공간을 구성하고, 각 차원의 가중치를 어떻게 부여할 것인가?
        - **기본 개념**: 일반적으로 단어(Term) 또는 N-gram (Bag-of-Words). 토픽 모델의 토픽 등도 가능.
        - **가정**: 기본 개념들은 서로 직교(Orthogonal)한다고 가정 (선형 독립, 의미적으로 겹치지 않음). 현실적으로는 어려운 가정이지만 계산을 위해 사용.
    2. **유사도 측정 방법**: 벡터 간의 유사도를 어떻게 정의할 것인가?
- **가중치 할당 (Weighting)**:
    - 벡터의 각 요소(차원)는 해당 개념의 중요도를 나타내는 가중치입니다.
    - **쿼리 측면**: 사용자의 정보 요구에서 각 개념(단어)의 중요도.
    - **문서 측면**: 해당 개념(단어)이 문서를 얼마나 잘 특징짓는지.
    - **두 가지 기본 휴리스틱**:
        1. **TF (Term Frequency, 단어 빈도)**: 특정 문서 내에서 단어가 얼마나 자주 등장하는가.
        2. **IDF (Inverse Document Frequency, 역문서 빈도)**: 특정 단어가 전체 문서 컬렉션에서 얼마나 드물게 등장하는가.
- **TF (Term Frequency) 가중치**:
    - **기본 아이디어**: 문서 내에서 단어가 더 자주 등장할수록 그 단어는 더 중요합니다.
    - **Raw TF**: $tf(t, d) = \text{단어 t가 문서 d에 등장한 횟수}$
    - **TF 정규화 (Normalization)**:
        - 문서 길이에 따른 편향 문제 (긴 문서가 단순히 단어가 많이 반복되어 높은 TF 값을 가질 수 있음).
        - 반복 등장의 정보 가치 감소 (첫 등장이 가장 중요).
        - **Sublinear TF Scaling**: $tf(t,d) = 1 + \log(f(t,d))$ if $f(t,d) > 0$ else $0$. (슬라이드 `[37]`의 `tf4`)
        - **Maximum TF Scaling (Double Normalization K)**: $tf(t,d) = K + (1-K) \frac{f(t,d)}{\max_w f(w,d)}$. (슬라이드 `[37]`의 `tf5`, `tf6`은 $K=0.5$)
- **IDF (Inverse Document Frequency) 가중치**:
    - **기본 아이디어**: 단어가 더 적은 수의 문서에 등장할수록 (즉, 희귀할수록) 그 단어는 더 변별력이 높습니다. (지프의 법칙과 연관)
    - **IDF 공식**: $idf(t) = \log \frac{N}{df(t)}$ (여기서 N은 총 문서 수, df(t)는 단어 t를 포함하는 문서 수). (슬라이드 `[35]`의 `idf2`)
        - 다양한 변형 존재 (예: $1 + \log(\frac{N}{df(t)})$, $\log(\frac{N}{1+df(t)})+1$ 등)
    - 문서 빈도(df) 대신 전체 단어 빈도(ttf)를 사용하지 않는 이유: 특정 문서 집합에서만 자주 등장하는 단어를 제대로 변별하지 못하기 때문.
- **TF-IDF 가중치**:
    - $w(t,d) = tf(t,d) \times idf(t)$
    - Gerard Salton 등에 의해 1980년대에 제안된 매우 유명하고 효과적인 문서 표현 방식입니다. (정보 검색 분야에서 여전히 널리 사용됨)
    - 문서 내에서 자주 등장하면서(High TF), 전체 컬렉션에서는 드물게 나타나는(High IDF) 단어에 높은 가중치를 부여합니다.
- **유사도 측정 (Similarity Measure)**:
    - **유클리드 거리**: 벡터 간의 직선 거리. 긴 문서에 불리할 수 있고, 벡터의 방향(의미)을 고려하지 못함.
    - **코사인 유사도 (Cosine Similarity)**: 두 벡터 사이의 각도의 코사인 값. 벡터의 크기(문서 길이)에 정규화되며, 벡터의 방향(단어 분포 패턴) 유사성을 측정.
        - $\cos(\vec{q}, \vec{d}) = \frac{\vec{q} \cdot \vec{d}}{||\vec{q}|| \cdot ||\vec{d}||}$
- **VSM의 장점**: 경험적으로 효과적, 직관적, 구현 용이, 많이 연구됨.
- **VSM의 단점**: 단어 독립성 가정(BoW), 쿼리와 문서를 동일하게 취급, 예측 적절성 부족(임의의 가중치 및 유사도), 많은 파라미터 튜닝 필요.

## 5. 역색인 (Inverted Index)

- **문서-단어 행렬(DTM)의 문제점**:
    - **공간 복잡도**: $O(D \times V)$ (D: 총 문서 수, V: 어휘 크기). 대부분의 값이 0인 희소 행렬(Sparse Matrix)로 공간 낭비 심함 (지프의 법칙에 따라 각 문서는 전체 어휘의 약 10%만 포함).
    - **시간 복잡도 (단순 검색 시)**: $O(L_q \times D \times L_d)$ ($L_q$: 쿼리 길이, $L_d$: 문서 길이). 매우 비효율적.
- **역색인 (Inverted Index) 구조**:
    - **현대 IR의 핵심 데이터 구조**.
    - 단어(Term)에서 해당 단어가 등장하는 문서들의 리스트(Posting List)로 매핑하는 조회 테이블.
    - **구성 요소**:
        - **사전 (Dictionary)**: 전체 어휘집. 각 단어와 해당 단어의 포스팅 리스트 시작 위치 등의 정보를 저장. (메모리에 상주, 빠른 랜덤 접근 필요 - 해시 테이블, B-트리, 트라이 등 사용)
        - **포스팅 (Postings)**: 각 단어에 대해 해당 단어가 나타나는 문서 ID(docID), 단어 빈도(term frequency), 단어 위치(term position) 등의 정보를 담고 있는 리스트. (디스크에 저장, 순차 접근 예상, 압축 필요)
    - **검색 시간 복잡도 (역색인 사용 시)**: $O(L_q \times |PL_{avg}|)$ ($|PL_{avg}|$: 평균 포스팅 리스트 길이). 지프의 법칙에 따라 $|PL_{avg}| \ll D$ 이므로 훨씬 효율적.
- **정렬 기반 역색인 구축 (Sorting-based Inverted Index Construction)**:
    1. 문서 파싱 및 (TermID, DocID, Count) 튜플 생성.
    2. DocID 기준으로 정렬.
    3. TermID 기준으로 "로컬" 정렬.
    4. 병합 정렬(Merge Sort)을 통해 전체 TermID 기준으로 정렬된 튜플 리스트 생성. 이를 통해 각 TermID에 대한 포스팅 리스트 구축.
    - 대용량 코퍼스도 단일 머신으로 색인 가능하며, MapReduce와 같은 분산 처리에도 적합.
- **동적 색인 업데이트 (Dynamic Index Update)**:
    - **주기적 재구축**: 변경이 적고 새로운 문서 누락 페널티가 작을 때 사용.
    - **보조 색인 (Auxiliary Index)**: 새로운 문서는 메모리 내 보조 색인에 저장하고, 임계값 초과 시 주기적으로 주 색인과 병합. (Logarithmic Merging)
- **색인 압축 (Index Compression)**:
    - **목표**: 저장 공간 절약, 캐시 효율성 증가, 디스크-메모리 전송률 향상. (주로 포스팅 파일 대상)
    - **기본 아이디어**: 포스팅 리스트 내 DocID는 정렬되어 있으므로, DocID 자체 대신 DocID 간의 차이(Gap)를 저장. 지프의 법칙에 따라 고빈도 단어는 Gap이 작고, 저빈도 단어는 포스팅 리스트가 짧음. → 편향된 분포를 이용한 압축.
    - **가변 길이 코딩 (Variable-length Coding)**: 작은 정수(고빈도)는 적은 비트로, 큰 정수(저빈도)는 많은 비트로 인코딩. (Unary, Gamma-code, Delta-code 등)
- **역색인을 이용한 검색**:
    - **쿼리 처리**: 쿼리 파싱, 문서와 동일한 전처리 적용.
    - **검색 절차**: 쿼리 용어 조회 → 포스팅 리스트 검색 → 연산 (AND, OR, NOT).
    - **AND 연산 최적화**: 여러 용어의 포스팅 리스트를 조인할 때, 가장 빈도가 낮은(포스팅 리스트가 짧은) 용어부터 시작.
- **구문 검색 (Phrase Query)**: "computer science"와 같이 정확한 구문 일치 검색.
    - N-gram 방식은 한계가 있음.
    - 역색인에 단어 위치 정보(Term Position)를 저장하여 해결.
    - 일반화된 포스팅 매칭: 두 쿼리 용어 간의 위치 패턴 조건 확인 (예: T2.pos - T1.pos = 1). 근접 검색(Proximity Query)도 가능.
- **철자 교정 (Spelling Correction)**:
    - 오타가 포함된 쿼리 처리 (예: "barck obama" → "barack obama").
    - **원칙**: 가장 가까운(편집 거리 기준) 올바른 철자 또는 가장 일반적인(빈도 높은) 올바른 철자 선택.
    - **편집 거리 (Edit Distance)**: 삽입, 삭제, 대체 연산을 통해 한 문자열을 다른 문자열로 변환하는 최소 횟수.
    - **최적화**: 접두사 고정, 문자 수준 역색인, 키보드 레이아웃 고려.
    - **쿼리 문맥 고려**: "flew form IAD" → "flew from IAD".
    - **음성적 유사도 (Phonetic Similarity)**: "herman" → "Hermann". (Phonetic Hashing)

## 7. 요약 및 결론

정보 검색 시스템의 평가는 검색 결과의 품질을 정량적으로 측정하기 위한 핵심 과정입니다. 정밀도, 재현율, MAP, NDCG 등의 다양한 평가 지표를 통해 시스템의 성능을 다각도로 평가할 수 있습니다. 특히 TREC과 같은 표준화된 평가 프레임워크는 서로 다른 검색 시스템의 객관적인 비교를 가능하게 합니다.

색인 기법에서는 역색인이 현대 정보 검색의 핵심 데이터 구조로, 효율적인 질의 처리를 위해 필수적입니다. 다양한 색인 최적화 기법들(압축, 위치 정보 추가, 분산 색인 등)을 통해 대규모 데이터에서도 빠른 검색 속도와 정확도를 보장할 수 있습니다.

또한 와일드카드 질의 처리, 스펠링 교정 등의 고급 검색 기능을 통해 사용자 경험을 향상시키고, 검색 시스템의 활용도를 높일 수 있습니다. 이러한 기술들은 현대 웹 검색 엔진의 기반이 되는 기술로, 대용량 정보에서 사용자가 원하는 정보를 빠르고 정확하게 찾을 수 있도록 도와줍니다.
